{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /global/homes/d/dsmorrow/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import necessary packages for further word processing\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2020)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to perform lemmatize and stem preprocessing steps on the data set.\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2142 5 15 discharge date 2142 5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admission date 2142 5 20 discharge date 2142 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admission date 2142 6 18 discharge date 2142 6...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admission date 2142 7 3 discharge date 2142 7 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admission date 2142 7 7 discharge date 2142 7 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323055</th>\n",
       "      <td>last name lf first name3 lf 1046 j last name ...</td>\n",
       "      <td>323055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323056</th>\n",
       "      <td>2143 9 3 9 59 am chest pa lat clip clip numbe...</td>\n",
       "      <td>323056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323057</th>\n",
       "      <td>2144 2 25 1 49 pm ankle ap mortise lat left c...</td>\n",
       "      <td>323057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323058</th>\n",
       "      <td>2144 1 7 4 21 pm ankle ap mortise lat left cl...</td>\n",
       "      <td>323058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323059</th>\n",
       "      <td>2144 8 25 2 45 pm ankle ap mortise lat left c...</td>\n",
       "      <td>323059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323060 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_processed   index\n",
       "0       admission date 2142 5 15 discharge date 2142 5...       0\n",
       "1       admission date 2142 5 20 discharge date 2142 6...       1\n",
       "2       admission date 2142 6 18 discharge date 2142 6...       2\n",
       "3       admission date 2142 7 3 discharge date 2142 7 ...       3\n",
       "4       admission date 2142 7 7 discharge date 2142 7 ...       4\n",
       "...                                                   ...     ...\n",
       "323055   last name lf first name3 lf 1046 j last name ...  323055\n",
       "323056   2143 9 3 9 59 am chest pa lat clip clip numbe...  323056\n",
       "323057   2144 2 25 1 49 pm ankle ap mortise lat left c...  323057\n",
       "323058   2144 1 7 4 21 pm ankle ap mortise lat left cl...  323058\n",
       "323059   2144 8 25 2 45 pm ankle ap mortise lat left c...  323059\n",
       "\n",
       "[323060 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_proc = pd.read_csv(\"Full_Table_ICD9_Notes.csv\", usecols=[\"text_processed\", \"index\"])\n",
    "full_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select for all the history section in the notes\n",
    "full_proc['history'] = full_proc[\"text_processed\"].apply(lambda st: st[st.find(\"history of present illness\")+len(\"history of present illness\"):st.find(\"physical exam\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>index</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2142 5 15 discharge date 2142 5...</td>\n",
       "      <td>0</td>\n",
       "      <td>24 year old female with sle esrd on hd hx mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admission date 2142 5 20 discharge date 2142 6...</td>\n",
       "      <td>1</td>\n",
       "      <td>ms known lastname is a 24 yo f with lupus sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admission date 2142 6 18 discharge date 2142 6...</td>\n",
       "      <td>2</td>\n",
       "      <td>please see micu note for full details in brie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admission date 2142 7 3 discharge date 2142 7 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>24f h o sle esrd on hd h o malignant htn svc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admission date 2142 7 7 discharge date 2142 7 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>24f h o sle esrd on hd h o malignant htn svc ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  index  \\\n",
       "0  admission date 2142 5 15 discharge date 2142 5...      0   \n",
       "1  admission date 2142 5 20 discharge date 2142 6...      1   \n",
       "2  admission date 2142 6 18 discharge date 2142 6...      2   \n",
       "3  admission date 2142 7 3 discharge date 2142 7 ...      3   \n",
       "4  admission date 2142 7 7 discharge date 2142 7 ...      4   \n",
       "\n",
       "                                             history  \n",
       "0   24 year old female with sle esrd on hd hx mal...  \n",
       "1   ms known lastname is a 24 yo f with lupus sin...  \n",
       "2   please see micu note for full details in brie...  \n",
       "3   24f h o sle esrd on hd h o malignant htn svc ...  \n",
       "4   24f h o sle esrd on hd h o malignant htn svc ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the sub headers in the history section\n",
    "full_proc['WO_Headers'] = full_proc[\"history\"].map(lambda x: re.sub('family history', '', x))\n",
    "full_proc['WO_Headers'] = full_proc[\"WO_Headers\"].map(lambda x: re.sub('social history', '', x))\n",
    "full_proc['WO_Headers'] = full_proc[\"WO_Headers\"].map(lambda x: re.sub('past medical history', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>index</th>\n",
       "      <th>history</th>\n",
       "      <th>WO_Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2142 5 15 discharge date 2142 5...</td>\n",
       "      <td>0</td>\n",
       "      <td>24 year old female with sle esrd on hd hx mal...</td>\n",
       "      <td>24 year old female with sle esrd on hd hx mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admission date 2142 5 20 discharge date 2142 6...</td>\n",
       "      <td>1</td>\n",
       "      <td>ms known lastname is a 24 yo f with lupus sin...</td>\n",
       "      <td>ms known lastname is a 24 yo f with lupus sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admission date 2142 6 18 discharge date 2142 6...</td>\n",
       "      <td>2</td>\n",
       "      <td>please see micu note for full details in brie...</td>\n",
       "      <td>please see micu note for full details in brie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admission date 2142 7 3 discharge date 2142 7 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>24f h o sle esrd on hd h o malignant htn svc ...</td>\n",
       "      <td>24f h o sle esrd on hd h o malignant htn svc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admission date 2142 7 7 discharge date 2142 7 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>24f h o sle esrd on hd h o malignant htn svc ...</td>\n",
       "      <td>24f h o sle esrd on hd h o malignant htn svc ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  index  \\\n",
       "0  admission date 2142 5 15 discharge date 2142 5...      0   \n",
       "1  admission date 2142 5 20 discharge date 2142 6...      1   \n",
       "2  admission date 2142 6 18 discharge date 2142 6...      2   \n",
       "3  admission date 2142 7 3 discharge date 2142 7 ...      3   \n",
       "4  admission date 2142 7 7 discharge date 2142 7 ...      4   \n",
       "\n",
       "                                             history  \\\n",
       "0   24 year old female with sle esrd on hd hx mal...   \n",
       "1   ms known lastname is a 24 yo f with lupus sin...   \n",
       "2   please see micu note for full details in brie...   \n",
       "3   24f h o sle esrd on hd h o malignant htn svc ...   \n",
       "4   24f h o sle esrd on hd h o malignant htn svc ...   \n",
       "\n",
       "                                          WO_Headers  \n",
       "0   24 year old female with sle esrd on hd hx mal...  \n",
       "1   ms known lastname is a 24 yo f with lupus sin...  \n",
       "2   please see micu note for full details in brie...  \n",
       "3   24f h o sle esrd on hd h o malignant htn svc ...  \n",
       "4   24f h o sle esrd on hd h o malignant htn svc ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_proc.to_csv('History_Notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_group1 = full_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [year, femal, esrd, malign, syndrom, posterior...\n",
       "1         [know, lastnam, lupu, esrd, malign, histori, s...\n",
       "2         [micu, note, detail, brief, woman, esrd, malig...\n",
       "3         [esrd, malign, syndrom, pre, prior, frequent, ...\n",
       "4         [esrd, malign, syndrom, pre, prior, frequent, ...\n",
       "                                ...                        \n",
       "323055    [chest, contrast, abdomen, contrast, clip, cli...\n",
       "323056    [clip, clip, number, radiolog, reason, eval, a...\n",
       "323057    [mortis, leav, clip, clip, number, radiolog, r...\n",
       "323058    [mortis, leav, clip, clip, number, radiolog, r...\n",
       "323059    [mortis, leav, clip, clip, number, radiolog, r...\n",
       "Name: WO_Headers, Length: 323060, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use preprocess function on the history section of the notes without headers included\n",
    "processed_docs = doc_group1['WO_Headers'].map(preprocess)\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 abdomin\n",
      "1 abus\n",
      "2 accid\n",
      "3 admit\n",
      "4 agre\n",
      "5 anemia\n",
      "6 antibodi\n",
      "7 anticardiolipin\n",
      "8 anticoagul\n",
      "9 apnea\n",
      "10 associ\n"
     ]
    }
   ],
   "source": [
    "#create dictionary of words\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out words that appear in less than (15) documents\n",
    "#only keep the first 10000\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through each document and report words and occurrences using doc2box for token id and amount\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "#bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(90, 0.01157092694043111),\n",
      " (158, 0.01607398170559334),\n",
      " (106, 0.02060247123983802),\n",
      " (56, 0.02316409571790551),\n",
      " (42, 0.026360408974084),\n",
      " (28, 0.026927212974133984),\n",
      " (133, 0.028460091686710386),\n",
      " (145, 0.029323390164209217),\n",
      " (122, 0.029754160832268093),\n",
      " (125, 0.03016918649471875),\n",
      " (144, 0.03059138532250271),\n",
      " (75, 0.03212258276223757),\n",
      " (81, 0.03317950358330767),\n",
      " (83, 0.03320847455858883),\n",
      " (93, 0.03321173187495516),\n",
      " (136, 0.03473065065038114),\n",
      " (117, 0.034863221470665666),\n",
      " (151, 0.03495781924052276),\n",
      " (97, 0.03496688243642581),\n",
      " (123, 0.03531442508866595),\n",
      " (52, 0.035374119636408366),\n",
      " (29, 0.035589415175223425),\n",
      " (49, 0.03583056904221277),\n",
      " (0, 0.03607206394014949),\n",
      " (19, 0.03655270349527521),\n",
      " (3, 0.0365961282108587),\n",
      " (73, 0.03738290103716312),\n",
      " (156, 0.03814627212856471),\n",
      " (30, 0.03815099040258024),\n",
      " (16, 0.03842001056934495),\n",
      " (130, 0.0389760740018324),\n",
      " (127, 0.0399458951937839),\n",
      " (129, 0.04020607254881963),\n",
      " (26, 0.04021689891375987),\n",
      " (77, 0.04047428067949276),\n",
      " (155, 0.040996966406151455),\n",
      " (87, 0.04198107963748346),\n",
      " (128, 0.042873426413658385),\n",
      " (24, 0.043038333789213984),\n",
      " (89, 0.043093161331691304),\n",
      " (159, 0.04491618911694768),\n",
      " (147, 0.04508561078192747),\n",
      " (103, 0.04567657311046727),\n",
      " (51, 0.04576642575990161),\n",
      " (13, 0.045822366331328857),\n",
      " (53, 0.04604923465792921),\n",
      " (108, 0.04627552965785181),\n",
      " (65, 0.04709287694392626),\n",
      " (120, 0.04797317128163886),\n",
      " (142, 0.048313311724218516),\n",
      " (85, 0.04836750114751187),\n",
      " (113, 0.049062464829200424),\n",
      " (110, 0.04931716681749247),\n",
      " (48, 0.049517041806266746),\n",
      " (126, 0.049742574864608126),\n",
      " (41, 0.049836057365695983),\n",
      " (114, 0.04984023972270514),\n",
      " (116, 0.05026738922350353),\n",
      " (25, 0.05157318910407444),\n",
      " (78, 0.05165851747679401),\n",
      " (40, 0.05198844734573374),\n",
      " (102, 0.052247795859265055),\n",
      " (148, 0.0523030636161841),\n",
      " (4, 0.05240484447014047),\n",
      " (37, 0.05260895455871889),\n",
      " (10, 0.05321111384052831),\n",
      " (64, 0.05332088331725063),\n",
      " (54, 0.053983354845286366),\n",
      " (5, 0.05412455733851774),\n",
      " (17, 0.05431030161566028),\n",
      " (115, 0.05432761696480366),\n",
      " (146, 0.05434321787115488),\n",
      " (143, 0.05465337680875657),\n",
      " (131, 0.05498998259118302),\n",
      " (95, 0.05519416050811255),\n",
      " (109, 0.055931475723761684),\n",
      " (1, 0.056107943563374583),\n",
      " (84, 0.0571138387677078),\n",
      " (31, 0.057114302662373634),\n",
      " (118, 0.058282911342950335),\n",
      " (21, 0.05834617642560008),\n",
      " (76, 0.05868044825115204),\n",
      " (23, 0.05934795836717269),\n",
      " (9, 0.06105869142120091),\n",
      " (59, 0.06305154206415715),\n",
      " (43, 0.06307634345336577),\n",
      " (112, 0.0632009686767116),\n",
      " (119, 0.06347565407325312),\n",
      " (57, 0.0635107450301296),\n",
      " (33, 0.06403065458507648),\n",
      " (139, 0.06420357679643665),\n",
      " (138, 0.06569322272545303),\n",
      " (44, 0.06613550838425641),\n",
      " (107, 0.06800889346221506),\n",
      " (105, 0.06869217335663776),\n",
      " (18, 0.06903429975586131),\n",
      " (50, 0.06951723168345166),\n",
      " (91, 0.06966567437402697),\n",
      " (121, 0.06979855790084402),\n",
      " (124, 0.07140884213403226),\n",
      " (22, 0.07254814057088532),\n",
      " (71, 0.07263585730087681),\n",
      " (8, 0.0737304895881661),\n",
      " (68, 0.07574444626149202),\n",
      " (2, 0.07756969178395269),\n",
      " (132, 0.07789914301807302),\n",
      " (55, 0.07864168135266417),\n",
      " (149, 0.07912174796138155),\n",
      " (82, 0.07962701287294813),\n",
      " (14, 0.08007268150484192),\n",
      " (96, 0.08058168406581245),\n",
      " (62, 0.08131621770010071),\n",
      " (63, 0.08155864147447911),\n",
      " (38, 0.0817511330543993),\n",
      " (27, 0.08293766568430332),\n",
      " (134, 0.08303113921627497),\n",
      " (99, 0.08515170716849631),\n",
      " (101, 0.0862617887448023),\n",
      " (74, 0.0871120846595528),\n",
      " (15, 0.08918933717083062),\n",
      " (35, 0.08965576365990517),\n",
      " (157, 0.0900796177273585),\n",
      " (154, 0.09092907177648202),\n",
      " (80, 0.09223366960288369),\n",
      " (69, 0.09337965722918712),\n",
      " (11, 0.09561646400846092),\n",
      " (150, 0.09887221570288451),\n",
      " (79, 0.09917829026198274),\n",
      " (20, 0.09963171331111884),\n",
      " (141, 0.10065746783943003),\n",
      " (60, 0.1007334889516052),\n",
      " (98, 0.10334944018647808),\n",
      " (39, 0.10449593548702953),\n",
      " (46, 0.10596936608044379),\n",
      " (36, 0.10609589972350117),\n",
      " (111, 0.10613226971375395),\n",
      " (7, 0.10862060243347049),\n",
      " (137, 0.10901229780203821),\n",
      " (67, 0.10921204537228703),\n",
      " (61, 0.11011425514822193),\n",
      " (47, 0.11070569298412608),\n",
      " (135, 0.1141120228565701),\n",
      " (45, 0.11435801865648432),\n",
      " (153, 0.11445274539075566),\n",
      " (66, 0.11612545401889895),\n",
      " (92, 0.11909218659965767),\n",
      " (58, 0.12073171979265367),\n",
      " (32, 0.12087678505235003),\n",
      " (88, 0.12535057905884106),\n",
      " (12, 0.12660913798319628),\n",
      " (104, 0.12911102639124838),\n",
      " (94, 0.131959772654334),\n",
      " (72, 0.1404291102917992),\n",
      " (70, 0.15823224252590817),\n",
      " (152, 0.16188891880137088),\n",
      " (34, 0.16312861934763517),\n",
      " (86, 0.17491259095718),\n",
      " (6, 0.18893798504183),\n",
      " (140, 0.20743355371903577),\n",
      " (100, 0.21724104155822682)]\n"
     ]
    }
   ],
   "source": [
    "#determine the TF-IDF scores or weight of a word within a document\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(sorted(doc, key = lambda x: x[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg ,thrombot ,antibodi ,lupu ,dialysi ,urgenc ,hypertens ,inabl ,month ,onset\n"
     ]
    }
   ],
   "source": [
    "#top ten weighted words\n",
    "print(dictionary[100] ,\",\" + dictionary[140] ,\",\" + dictionary[6] ,\",\" + dictionary[86] ,\",\" + dictionary[34] ,\",\" + dictionary[152] ,\",\" + dictionary[70],\",\" + dictionary[72],\",\" + dictionary[94],\",\" + dictionary[104])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train LDA model using BOW, chunk size is 5000 documents, lda is updated after every chunk size, 2 full passes through the corpus for training, produce 10 topics\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=5000,\n",
    "                                           passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.023*\"plan\" + 0.020*\"respons\" + 0.019*\"assess\" + 0.019*\"action\" + '\n",
      "  '0.016*\"continu\" + 0.011*\"monitor\" + 0.010*\"pain\" + 0.009*\"give\" + '\n",
      "  '0.009*\"remain\" + 0.008*\"follow\"'),\n",
      " (1,\n",
      "  '0.019*\"vein\" + 0.019*\"right\" + 0.017*\"procedur\" + 0.016*\"arteri\" + '\n",
      "  '0.015*\"leav\" + 0.013*\"identifi\" + 0.012*\"reason\" + 0.012*\"clip\" + '\n",
      "  '0.012*\"cathet\" + 0.011*\"patient\"'),\n",
      " (2,\n",
      "  '0.024*\"contrast\" + 0.019*\"right\" + 0.018*\"leav\" + 0.018*\"hemorrhag\" + '\n",
      "  '0.016*\"head\" + 0.015*\"clip\" + 0.013*\"reason\" + 0.012*\"mass\" + 0.010*\"year\" '\n",
      "  '+ 0.009*\"acut\"'),\n",
      " (3,\n",
      "  '0.033*\"medic\" + 0.026*\"hour\" + 0.023*\"total\" + 0.022*\"balanc\" + '\n",
      "  '0.018*\"rhythm\" + 0.017*\"review\" + 0.017*\"allergi\" + 0.016*\"system\" + '\n",
      "  '0.015*\"mmhg\" + 0.014*\"admiss\"'),\n",
      " (4,\n",
      "  '0.055*\"trace\" + 0.036*\"previou\" + 0.033*\"chang\" + 0.030*\"wave\" + '\n",
      "  '0.026*\"compar\" + 0.019*\"lead\" + 0.018*\"leav\" + 0.016*\"abnorm\" + '\n",
      "  '0.015*\"ventricular\" + 0.012*\"infarct\"'),\n",
      " (5,\n",
      "  '0.046*\"assess\" + 0.045*\"lung\" + 0.042*\"sound\" + 0.034*\"ventil\" + '\n",
      "  '0.031*\"breath\" + 0.023*\"comment\" + 0.021*\"airway\" + 0.020*\"continu\" + '\n",
      "  '0.019*\"cuff\" + 0.018*\"sputum\"'),\n",
      " (6,\n",
      "  '0.028*\"reason\" + 0.025*\"chest\" + 0.025*\"clip\" + 0.021*\"right\" + '\n",
      "  '0.018*\"leav\" + 0.018*\"effus\" + 0.016*\"year\" + 0.016*\"pleural\" + '\n",
      "  '0.016*\"tube\" + 0.016*\"examin\"'),\n",
      " (7,\n",
      "  '0.019*\"patient\" + 0.016*\"pain\" + 0.016*\"hospit\" + 0.010*\"transfer\" + '\n",
      "  '0.008*\"assess\" + 0.007*\"plan\" + 0.007*\"respons\" + 0.007*\"histori\" + '\n",
      "  '0.007*\"deni\" + 0.007*\"action\"'),\n",
      " (8,\n",
      "  '0.025*\"contrast\" + 0.016*\"clip\" + 0.014*\"right\" + 0.013*\"reason\" + '\n",
      "  '0.011*\"leav\" + 0.010*\"abdomen\" + 0.010*\"pelvi\" + 0.009*\"fractur\" + '\n",
      "  '0.009*\"see\" + 0.009*\"small\"'),\n",
      " (9,\n",
      "  '0.048*\"valv\" + 0.046*\"normal\" + 0.031*\"aortic\" + 0.027*\"leav\" + '\n",
      "  '0.024*\"mitral\" + 0.020*\"leaflet\" + 0.020*\"ventricular\" + 0.018*\"systol\" + '\n",
      "  '0.017*\"wall\" + 0.017*\"mild\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keywords in the 10 topics using the BOW corpus\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train LDA model using TFIDF corpus, chunk size is 5000 documents, lda is updated after every chunk size, 2 full passes through the corpus for training, produce 10 topics\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus_tfidf,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=5000,\n",
    "                                           passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.007*\"action\" + 0.007*\"respons\" + 0.006*\"patient\" + 0.006*\"transfer\" + '\n",
      "  '0.006*\"pain\" + 0.005*\"assess\" + 0.005*\"plan\" + 0.004*\"deni\" + 0.004*\"home\" '\n",
      "  '+ 0.004*\"daili\"'),\n",
      " (1,\n",
      "  '0.016*\"liver\" + 0.012*\"ascit\" + 0.012*\"obstruct\" + 0.011*\"hepat\" + '\n",
      "  '0.011*\"bowel\" + 0.010*\"abdomen\" + 0.010*\"abdomin\" + 0.009*\"gallbladd\" + '\n",
      "  '0.009*\"portal\" + 0.008*\"kidney\"'),\n",
      " (2,\n",
      "  '0.018*\"contrast\" + 0.008*\"fractur\" + 0.007*\"hemorrhag\" + 0.007*\"clip\" + '\n",
      "  '0.007*\"right\" + 0.006*\"mass\" + 0.006*\"reason\" + 0.005*\"imag\" + 0.005*\"leav\" '\n",
      "  '+ 0.005*\"pelvi\"'),\n",
      " (3,\n",
      "  '0.041*\"sound\" + 0.030*\"comment\" + 0.028*\"ventil\" + 0.025*\"lung\" + '\n",
      "  '0.023*\"breath\" + 0.023*\"cuff\" + 0.022*\"ideal\" + 0.021*\"assess\" + '\n",
      "  '0.020*\"airway\" + 0.019*\"type\"'),\n",
      " (4,\n",
      "  '0.078*\"trace\" + 0.045*\"wave\" + 0.043*\"previou\" + 0.031*\"compar\" + '\n",
      "  '0.026*\"lead\" + 0.021*\"diagnost\" + 0.020*\"ventricular\" + 0.019*\"specif\" + '\n",
      "  '0.018*\"abnorm\" + 0.018*\"chang\"'),\n",
      " (5,\n",
      "  '0.018*\"vein\" + 0.012*\"spine\" + 0.009*\"femor\" + 0.009*\"compress\" + '\n",
      "  '0.009*\"extrem\" + 0.009*\"cervic\" + 0.008*\"carotid\" + 0.008*\"fusion\" + '\n",
      "  '0.007*\"cord\" + 0.007*\"clip\"'),\n",
      " (6,\n",
      "  '0.015*\"reason\" + 0.014*\"clip\" + 0.014*\"chest\" + 0.012*\"effus\" + '\n",
      "  '0.012*\"portabl\" + 0.012*\"pleural\" + 0.011*\"tube\" + 0.010*\"pneumothorax\" + '\n",
      "  '0.010*\"radiograph\" + 0.010*\"interv\"'),\n",
      " (7,\n",
      "  '0.020*\"balanc\" + 0.018*\"system\" + 0.017*\"hour\" + 0.017*\"total\" + '\n",
      "  '0.015*\"review\" + 0.015*\"rhythm\" + 0.014*\"mmhg\" + 0.014*\"allergi\" + '\n",
      "  '0.012*\"admiss\" + 0.010*\"medic\"'),\n",
      " (8,\n",
      "  '0.012*\"action\" + 0.011*\"respons\" + 0.009*\"plan\" + 0.009*\"assess\" + '\n",
      "  '0.008*\"continu\" + 0.005*\"pain\" + 0.005*\"wean\" + 0.005*\"cont\" + 0.005*\"give\" '\n",
      "  '+ 0.005*\"remain\"'),\n",
      " (9,\n",
      "  '0.033*\"valv\" + 0.019*\"mitral\" + 0.019*\"aortic\" + 0.017*\"normal\" + '\n",
      "  '0.017*\"leaflet\" + 0.012*\"ventricular\" + 0.012*\"doppler\" + 0.011*\"systol\" + '\n",
      "  '0.011*\"mildli\" + 0.011*\"wall\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keywords in the 10 topics using the TFIDF corpus instead\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-intern]",
   "language": "python",
   "name": "conda-env-.conda-intern-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
